# Домашнее задание к занятию "10.01. Зачем и что нужно мониторить" - Захаров Сергей Николаевич

## Обязательные задания

#### Вопрос №1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя  платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой  осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

**Ответ:**

Вероятно, что на платформе существует низкопроизводительный компонент, который создает "бутылочное горлышко" при вычислениях.
Это может быть недостаточный размер RAM (при этом будет идти активный свопинг), слабый для наших вычислений CPU (при этом его загрузка будет близка к 100%). Также причина может быть в образования большой очереди при передаче (по сети) файлов малого размера. 
Поэтому для определения причины высокой загрузки CPU необходимо включить в мониторинг следующие метрики:

* Згрузка RAM
* Згрузка CPU
* Размер SWAP
* Температура HDD
* Свободное место на HDD
* кол-во операций чтения HDD
* кол-во операций записи HDD
* Скорость записи на HDD
* Скорость чтения на HDD
* кол-во свободных inodes
* кол-во созданных файлов нужного формата в контролируемом каталоге
* кол-во удаленных файлов нужного формата в контролируемом каталоге
* Минимальный размер создаваемого файла нужного формата
* Максимальный размер создаваемого файла нужного формата
* Кол-во файлов размером менее 10кб
* Кол-во сессий TCP в состоянии `TIME-WAIT`, `ESTABLISHED`, `SYN-SENT`, `CLOSING` 

#### Вопрос №2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

**Ответ:**

Необходимо уточнить у менеджера продукта какие действуют SLO, SLA. Затем получить из мониторинга SLI, сравнить его с SLO. Так мы сможем узнать насколько мы выполняем свои обязятельства перед клиентами и какое результирующее качество обслуживания. 

Можно предположить, что проект заключается в создании документов для бухгалтерской отчетности при проведении ежедневных операций продаж на нескольких площадках (филиалах) компании. В таком случае, параметрами качества обслуживания можно взять кол-во подготовленных документов (финансовых отчетов) за период времени. Т.е. производительность создания документов. Высокая нагрузка на CPU приводит к невозможности формировать отчеты, соответствено падает производительность.

Требования клиента по созданию отчетов:
- 500 шт./час для документов размером менее 500000 байт
- 200 шт./час для документов размером от 500001 байт до 1000000 байт
- 100 шт./час для документов размером от 1000001 байт до 5000000 байт 
- 50 шт./час для документов размером от 5000001 байт до 10000000 байт 
- 10 шт./час для документов размером от 10000001 байт до 15000000 байт
- Для файлов размером более 15000000 байт - параметра требование не предусмотрено по причине малой вероятости появления файлов такого размера.
- Итого: 860 шт./час

Технически мы гарантируем формирование такого количества отчетов в час:
- 490 шт./час для документов размером менее 500000 байт
- 195 шт./час для документов размером от 500001 байт до 1000000 байт
- 95 шт./час для документов размером от 1000001 байт до 5000000 байт 
- 48 шт./час для документов размером от 5000001 байт до 10000000 байт 
- 9 шт./час для документов размером от 10000001 байт до 15000000 байт
- Итого: 837 шт./час

В принятом с клиентом соглашении SLO = 97.325%. 

Переводим наше соглашение в SLA:
- SLA-500 = 490 шт./час для документов размером менее 500000 байт
- SLA-1000 = 195 шт./час для документов размером от 500001 байт до 1000000 байт
- SLA-5000 = 95 шт./час для документов размером от 1000001 байт до 5000000 байт 
- SLA-10000 = 48 шт./час для документов размером от 5000001 байт до 10000000 байт 
- SLA-15000 = 9 шт./час для документов размером от 10000001 байт до 15000000 байт
- Для файлов размером более 15000000 байт - параметра SLA не предусмотрен
- SLA-All: 837 шт./час


В систему мониторинга необходимо добавить метрики, высчитывающие кол-во созданных файлов в час:
* размером менее 500000 байт
* размером от 500001 байт до 1000000 байт
* размером от 1000001 байт до 5000000 байт 
* размером от 5000001 байт до 10000000 байт 
* размером от 10000001 байт до 15000000 байт
* размером более 15000000 байт - для статистики появления таких файлов и контроля за нагрузкой на наши вычислительные ресурсы.

Из систем мониторинга gолучаем SLI для каждого типа SLA. Затем высчитываем итоговый SLI по формуле (это делается в истеме мониторинга и выводится в виде графика):
```
(SLI_500 + SLI_1000 + SLI_5000 + SLI_10000 + SLI_15000) / SLI_All

```
Далее сравниваем с итоговый SLI с SLO и получаем ответ на вопрос менеджера о том, как мы выполняем свои обязанности перед клиентами и какое у нас качество обслуживания.

Что касается высокой загрузки CPU (в задаче №1), то нужно будет отследить соответствие нагрузки на CPU с поведением параметров всех метрик.

#### Вопрос №3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

**Ответ:**

Предположим, что ошибки приложений состоят из:
- ввод некорректных данных от клиентов
- синтаксические ошибки
- математические ошибки
- алгоритмические ошибки
- сессии TCP в состоянии 

Для сбора логов 

Для локально развертываемого решения можно использовать такие свободные системы мониторинга:
- [Sentry](https://sentry.io/welcome/). 
  - Преимущества: свободное ПО, Специально разработано для поиска ошибок. 
  - Недостатки:
- [Grafana + Prometheus + Nodexporter]()
  - Преимужества:
  - Недостатки:
- [Telegraf + Infuxdb + Kapacitor + Chronograf]()
  - Преимужества:
  - Недостатки:
- [New Relic](https://newrelic.com/platform/errors-inbox) Позволяет просматривать все ошибки с полным контекстом в одном месте. Ускоряет поиск первопричины благодаря полной информации об ошибке, включая stack traces.
  - Преимужества:
  - Недостатки:
- Syslog + Grep - решение, основанное на сборе всех логов с поиском ошибок приложений по заданным в скриптах шаблонам. 
  - Преимужества:
  - Недостатки: 
- стэк [ELK](https://www.elastic.co/elastic-stack/)
  - Преимужества:
  - Недостатки:


В случае облачного решения:
- [Data Dog](https://www.datadoghq.com/)
  - Преимужества:
  - Недостатки:




 * Можно использовать свободное ПО
   * DataDog
   * New Relic
   * Локальный Elasticsearch
   * Syslog в текстовом формате, а потом грепать и фильтровать
   * Нужно привести 2-3 решения с их плюсами и минусамим

#### Вопрос №4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: `summ_2xx_requests/summ_all_requests`. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

**Ответ:**

В нашей системе считаются только успешные запросы. Это такие запросы, в число которых не входят ошибки клиента (4хх) и ошибки сервера (5хх),
В дополнение к этому, в представленной формуле недостает учета ошибок перенаправления (3хх). Отсюда и получаются некорректные данные.

Для корректного вычисления параметра SLI необходимо производить его вычисление по следующей формуле:

```
SLI = (сумма_запрсов_2xx + сумма_запрсов_3xx)/(сумма_всех_запрсов_)
```

#### Дополнительное задание (со звездочкой*) - необязательно к выполнению

Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
