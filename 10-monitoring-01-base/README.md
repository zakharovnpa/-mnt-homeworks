# Домашнее задание к занятию "10.01. Зачем и что нужно мониторить" - Захаров Сергей Николаевич

## Обязательные задания

#### Вопрос №1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя  платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой  осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

**Ответ:**

1. Вероятно, что на платформе существует низкопроизводительный компонент, который создает "бутылочное горлышко" при вычислениях.
Это может быть недостаточный размер RAM (при этом будет идти активный свопинг), слабый для наших вычислений CPU (при этом его загрузка будет близка к 100%). Также причина может быть в образования большой очереди при передаче (по сети) файлов малого размера. 
2. Поэтому для определения причины высокой загрузки CPU необходимо включить в мониторинг следующие метрики:

| Метрика |Назначение|
|:-|:-|
загрузка RAM |  контроль за потреблением оперативной памяти
загрузка CPU |  контроль за нагрузкой на процессор
размер SWAP |  контроль за процессом свопинга, когда недостаточно оперативной памяти
температура HDD | при высокой температуре возможно снижение производительности HDD
свободное место на HDD | контроль за достаточным свободным местом на HDD и за расходом физической памяти
кол-во операций чтения HDD | контроль производительности HDD
кол-во операций записи HDD | контроль производительности HDD
скорость записи на HDD | контроль производительности HDD
скорость чтения на HDD | контроль производительности HDD
кол-во свободных inodes | контроль возможности создания новых файлов
кол-во созданных файлов нужного формата в контролируемом каталоге| статистика и контроль нагрузки на файловую систему
кол-во удаленных файлов нужного формата в контролируемом каталоге| статистика и контроль нагрузки на файловую систему
минимальный размер создаваемого файла нужного формата| статистика и контроль нагрузки на файловую систему
максимальный размер создаваемого файла нужного формата| статистика и контроль нагрузки на файловую систему
кол-во создаваемых файлов размером менее 10кб| статистика и контроль нагрузки на файловую систему
кол-во сессий TCP в состоянии `TIME-WAIT`, `ESTABLISHED`, `SYN-SENT`, `CLOSING` | контроль нагрузки на процесс передачи данных

#### Вопрос №2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

**Ответ:**

1. Необходимо уточнить у менеджера продукта какие действуют SLO, SLA. Затем получить из мониторинга SLI, сравнить его с SLO. Так мы сможем узнать насколько мы выполняем свои обязятельства перед клиентами и какое результирующее качество обслуживания. 

2. Можно предположить, что проект заключается в создании документов для бухгалтерской отчетности при проведении ежедневных операций продаж на нескольких площадках (филиалах) компании. В таком случае, параметрами качества обслуживания можно взять кол-во подготовленных документов (финансовых отчетов) за период времени 1 час, т.е. производительность создания документов. Высокая нагрузка на CPU влияет на скорость формирования отчетов, соответствено падает производительность.

3. Требования клиента по созданию отчетов:

|Размер файла документа, байт|шт./час|
|:-:|:-:|
| < 500000|500 |
|от 500001 до 1000000|200|
|от 1000001 до 5000000|100| 
|от 5000001 до 10000000|50| 
|от 10000001 до 15000000|10| 
|более 15000000 байт|не предусмотрено по причине малой вероятости появления файлов такого размера|
|Итого:| 860 |

4. Технически мы гарантируем формирование такого количества отчетов в час:

|Размер файла документа, байт|шт./час|
|:-----------:|:--------------:|
| < 500000|490 |
|от 500001  до 1000000|195|
|от 1000001  до 5000000|95| 
|от 5000001  до 10000000|48| 
|от 10000001 до 15000000|9| 
|Итого:| 837 |

**В принятом с клиентом соглашении SLO = 97.325%**

5. Переводим наше соглашение в SLA:

|Название SLA|Размер файла документа, байт|шт./час|
|:-----------:|:--------------:|:----:|
|SLA_500| < 500000|490 |
|SLA_1000|от 500001  до 1000000|195|
|SLA_5000|от 1000001  до 5000000|95| 
|SLA_10000|от 5000001  до 10000000|48| 
|SLA_15000 |от 10000001 до 15000000|9| 
|SLA_All|от 500000 до 15000000|837|


6. В систему мониторинга необходимо добавить метрики, высчитывающие кол-во созданных файлов требуемого формата за 1 час:

|Метрика |Назначение |
|:-|:-|
создано файлов размером менее 500000 байт| для вычисления SLI_500
создано файлов размером от 500001 байт до 1000000 байт|для вычисления SLI_1000
создано файлов размером от 1000001 байт до 5000000 байт |для вычисления SLI_5000
создано файлов размером от 5000001 байт до 10000000 байт |для вычисления SLI_10000
создано файлов размером от 10000001 байт до 15000000 байт|для вычисления SLI_15000
создано файлов размером более 15000000 байт| для статистики появления таких файлов и контроля за нагрузкой на наши вычислительные ресурсы.

7. Из систем мониторинга gолучаем SLI для каждого типа SLA. 
8. Затем высчитываем итоговый SLI в ` % ` по формуле (это делается в истеме мониторинга и выводится в виде графика):
```
(SLI_500 + SLI_1000 + SLI_5000 + SLI_10000 + SLI_15000) / SLI_All * 100

```
9. Далее сравниваем с итоговый SLI с SLO и получаем ответ на вопрос менеджера о том, как мы выполняем свои обязанности перед клиентами и какое у нас качество обслуживания.

10. Что касается высокой загрузки CPU (в задаче №1), то нужно будет отследить соответствие нагрузки на CPU с поведением параметров всех метрик, выявить причину создания высокой нагрузки на CPU и создать задачу на решение проблемы.

#### Вопрос №3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

**Ответ:**

1. Для сбора логов и ошибок приложений можно внедрить систему мониторинга уровня OpenSource. 
2. Вот некоторые системы и их свойства для выбора:

| System|Преимущества|Недостатки|
|:-|-|-|
|[Sentry](https://sentry.io/welcome/)|OpenSource. Специально разработано для отслеживания ошибок приложений. Большое количество настроек, гибкость настроек нотификаци. Есть система алертов. Большое число платформ для интеграции. Есть библиотека SentrySDK для отлова событий и отправки в Sentry  |Есть два решения Sentry - Cloud и Self-hosted. Аналогичную Cloud-архитектуру возможно использовать и в Self-hosted системе, но это влечет большие затраты по обслуживанию. |
|[Prometheus + Nodexporter + Grafana]()|OpenSource. Быстрое развертывание. Простое создание графиков. Nodexporter как агент собирает и направляет метрики на обработку и хранение. Есть система алертов. Grafana - красивый веб интерфейс с гибкимим настройками. Есть готовые шаблоны Дашборд в сообществе. | Необходимость подключения дополнительных плагинов. В некоторых случаях обсчёт графиков происходит на стороне клиента  |
|[Telegraf + Infuxdb + Kapacitor + Chronograf]()|OpenSource. Telegraf можно развернуть в качестве сборщика системных журналов с помощью подключаемого модуля Telegraf Syslog. Сообщения системного журнала отправляются с контролируемого устройства на IP-адрес коллектора. |Требуется предварительная настройка через конфигурационные файлы|
|Syslog + Grep| Решение, основанное на сборе всех логов приложений с поиском ошибок по заданным в скриптах шаблонам.|Требуется знание ЯП, регулярных выражений для написание скриптов. Требуется настройка работы скриптов. Для наглядности и построения графиков также требуется доп. разработка|
|[Data Dog](https://www.datadoghq.com/) | Отлично интегрируется с NGINX Ingress и позволяет производить сквозную трассировку с момента поступления запроса в кластер, а также позволяет принимать метрики `statsd`, собирать логи и метрики хостов|Облачное решение для облачных структур |

3. Некоторые платные решения для сравнения:

| System|Преимущества|Недостатки|
|:-|-|-|
|[New Relic](https://newrelic.com/platform/errors-inbox)|Обнаружение, сортировка и устранение ошибок для критически важных объектов и служб на одном экране. Ускоряет поиск первопричины благодаря полной информации об ошибке, включая stack traces. |Платное ПО. Облачная платформа для аналитики ПО. Агент New Relic работает по проприетарным протоколам, в нём нет поддержки OpenTracing. Для расширенной инструментации требуется вносить правки специально для New Relic|
|Стэк [ELK](https://www.elastic.co/elastic-stack/)| Система фильтрации приема собщений от источника. На минимальных конфигурациях это свободное ПО, но его расширение и увеличение возможностей требует приобретения нужных компонентов|Написаy на Java. Требуется инфраструктура со значительными вычислительными ресурсами.|

4. Выбор системы необходимо делать с учетом того, что средств могут не выделять еще несколько лет и тогда внедряемая система станет основной на длительный период. Таким образом, преимущества СМ при выборе будут заключаться в наличии расширяемости задач, решаемых СМ, кроме поиска и анализа ошибок приложений. 
5. Мой выбор системы:
  - приоритетно - Sentry. Т.к. OpenSource и специализированная
  - менее приоритетно - Prometheus + Nodexporter + Grafana. Также OpenSource, но более универсальная по решаемым задачам.

#### Вопрос №4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: `summ_2xx_requests/summ_all_requests`. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

**Ответ:**

1. В нашей системе считаются только успешные запросы. Это такие запросы, в число которых не входят ошибки клиента (4хх) и ошибки сервера (5хх),
2. В дополнение к этому, в представленной формуле недостает учета ошибок перенаправления (3хх). Отсюда и получаются некорректные данные.
3. Для корректного вычисления параметра SLI в ` % ` необходимо производить его вычисление по следующей формуле:

```
SLI = (сумма_запрсов_2xx + сумма_запрсов_3xx)/(сумма_всех_запрсов_) * 100
```

#### Дополнительное задание (со звездочкой*) - необязательно к выполнению

Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

**Ответ:**

1. Скрипт для сбора метрик

```py
#!/usr/bin/env python3

# Скрипт сбора логов на основе метрик из локальной директории /proc

import os
import json
import datetime

# Директория для складывания логов
flog = "/var/log/"

bashCommand = ["cd /proc", "cat stat", "cat meminfo", "cat loadavg", "cat vmstat", "cat diskstats"]
result_os = os.popen(' && '.join(bashCommand)).read()
for result in result_os.split('\n'):
    if result.find('MemFree') != -1:
        prepare_result_1 = result.replace('', '')
        print(prepare_result_1[18:-2])
    elif result.find('MemAvailable') != -1:
        prepare_result_2 = result.replace('', '')
    elif result.find('cpu ') != -1:
        prepare_result_3 = result.replace('', '')
    elif result.find('0.') != -1:
        prepare_result_4 = result.replace('', '')
    elif result.find('1.') != -1:
        prepare_result_4 = result.replace('', '')
    elif result.find('nr_free_p') != -1:
        prepare_result_6 = result.replace('', '')
    elif result.find('sda5') != -1:
        prepare_result_7 = result.replace('', '')

# Фиксируем время сбора логов:
with open(flog + str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M")) + '-awesome-monitoring.log', 'w') as jsf:
    json_data = json.dumps({'Date': str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M"))}, indent=2)
    jsf.write(json_data)
# Фиксируем метрику MemFree
with open(flog + str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M")) + '-awesome-monitoring.log', 'a') as jsf:
    json_data = json.dumps({'MemFree, kB':prepare_result_1[18:-2]}, indent=2)
    jsf.write(json_data)
# Фиксируем метрику MemAvailable
with open(flog + str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M")) + '-awesome-monitoring.log', 'a') as jsf:
    json_data = json.dumps({'MemAvailable, kB':prepare_result_2[17:-2]}, indent=2)
    jsf.write(json_data)
# Фиксируем метрику cpu
with open(flog + str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M")) + '-awesome-monitoring.log', 'a') as jsf:
    json_data = json.dumps({'CPU, %':prepare_result_3[5:-41]}, indent=2)
    jsf.write(json_data)
# Фиксируем метрику avgCPU
with open(flog + str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M")) + '-awesome-monitoring.log', 'a') as jsf:
    json_data = json.dumps({'avgCPU, %':prepare_result_4[:-12]}, indent=2)
    jsf.write(json_data)
with open(flog + str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M")) + '-awesome-monitoring.log', 'a') as jsf:
    json_data = json.dumps({'nr_free_p':prepare_result_6[14:]}, indent=2)
    jsf.write(json_data)
# Фиксируем метрику HDD sda5
with open(flog + str(datetime.datetime.now().strftime("%Y-%m-%d--%H:%M")) + '-awesome-monitoring.log', 'a') as jsf:
    json_data = json.dumps({'HDD sda5':prepare_result_7[18:-80]}, indent=2)
    jsf.write(json_data)

```


2. Конфигурация cron-расписания

* Файл расписания `start-cron-log-script.sh`

```sh
* * * * * /root/PycharmProjects/python-lesson-10.1/./my-log-script.py
```


3. Пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей

```js
{
  "Date": "2022-05-01--12:44"
}{
  "MemFree, kB": "207708 "
}{
  "MemAvailable, kB": "4836048 "
}{
  "CPU, %": "2532546 "
}{
  "avgCPU, %": "1.17 0.81 0.68 "
}{
  "nr_free_p": "51927"
}{
  "HDD sda5": "92782 "
}
```



---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
