# Домашнее задание к занятию "10.06. Инцидент-менеджмент" - Захаров Сергей Николаевич

## Задание 

Составьте постмортем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

**Ответ:**
1. Краткое описание инцидента (краткая выжимка о инциденте)

Из-за кратковременного отсутствия связи между Восточным и Западным ЦОД кластеры БД стали содержать различные данные за период отсутствия связи (43 секунды). После возобновления связи кластеры БД для восстановления целостности БД начали процесс репликации с Восточного ЦОД на Западный и с Западного ЦОД на Восточный. Это привело к высокой нагрузке на каналы связи, повышенной задержке при передаче данных (латентности) и непредсказуемому времени восстановления целостности БД из-за режима перерепликации. Для преодоления данной ситуации была выполнена временная приостановка функции записи новых данных в БД, что снизило трафик репликации и снизило латентность. В ручном режиме из резервных копий были восстановлены данные в Восточном ЦОД. Затем включен режим репликации с Западным ЦОД. Когда доступность сайта восстановилась до нормы, включен режим записи новых данных и восстановлены все сервисы сайта.

2. Предшествующие события (что произошло перед инцидентом)

Вышло из строя оптическое оборудование 100G в Восточном ЦОД. При проектировании топологии кластера было отсутсвие условий для резервирования сетевого оборудования в ЦОД.

3. Причина инцидента (из-за чего возник инцидент)

Пропала связь с сетевым концентраторм Восточного ЦОД. Отсутствие оборудования для резервирования затронутой аварией линиии связи.

4. Воздействие (на что повлиял инцидент)

Произошло разделение записей в БД сайта. Восточный ЦОД и Западный ЦОД стали содержать различные данные.

5. Обнаружение (когда и как инцидент был обнаружен)

Внутренние системы мониторинга генерировали предупреждения, указывающие на многочисленные сбои в системах. Иженеры группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии. 

6. Реакция (кто ответил на инцидент, кто был привлечен, какие каналы коммуникации были задействованы)

Инженеры, участвующие в группе реагирования на инциденты, начали разработку плана по устранению несоответствий данных и внедрению наших процедур аварийного переключения для MySQL.
К решению проблемы присоединился координатор инцидента.
Были вызваны дополнительные инженеры из группы разработки баз данных GitHub. 
В блоге были сообщения для пользователей о статусе сайта и планируемом времени восстановления полной работоспособности всех сервисов сайта.

7. Восстановление (описание действий по устранению инцидента и поведение системы)

В Восточном ЦОД восстановлены несколько кластеров из резервных копий. Началась репликация новых данных с Западного ЦОД. Определен способ восстановления данных на Западном ЦОД, для преодоления ограничения пропускной способности, вызванные загрузкой из внешнего хранилища. В Восточном ЦОД установлены  первичные БД. Сайт стал гораздо более отзывчивым, так как записи теперь направлялись на сервер базы данных, расположенный в том же физическом ЦОД, что и  уровень приложений. Распределена нагрузка чтения по большому пулу реплик чтения. Каждый запрос к службам сайта попадает в реплику чтения, которая задерживалась на несколько часов. Начали предоставлять дополнительные реплики чтения MySQL в общедоступном облаке Восточного ЦОД. Как только они стали доступны, стало проще распределять объем запросов на чтение по большему количеству серверов. Как только реплики были синхронизированы, было выполнено  аварийное переключение на исходную топологию. Статус инцидента продолжал оставаться красным. Был увеличен TTL для полезных нагрузок веб-перехватчиков для гарантированной ручной обработки этих данных. 





#### 22 октября 2018 г., 06:51 UTC
* Восстановление
* 
Несколько кластеров завершили восстановление из резервных копий в нашем центре обработки данных на восточном побережье США и начали репликацию новых данных с западного побережья. 

Это привело к медленной загрузке сайта для страниц, которые должны были выполнить операцию записи по межстрановой ссылке, но страницы, читающие из этих кластеров баз данных, возвращали актуальные результаты, если запрос на чтение попадал на только что восстановленную реплику. 

Другие более крупные кластеры баз данных все еще восстанавливались.

Наши команды определили способы восстановления непосредственно с западного побережья, чтобы преодолеть ограничения пропускной способности, вызванные загрузкой из внешнего хранилища, и все больше убеждались в том, что восстановление неизбежно, а время, оставшееся до установления работоспособной топологии репликации, зависело от того, как долго она будет работать. взять репликацию, чтобы наверстать упущенное. 

Эта оценка была линейно интерполирована на основе имеющейся у нас телеметрии репликации, а страница состояния была обновлена , чтобы установить ожидаемое время восстановления в два часа.

#### 22 октября 2018 07:46 UTC
GitHub опубликовал сообщение в блоге , чтобы предоставить больше контекста. Мы используем GitHub Pages для внутренних целей, и все сборки были приостановлены несколькими часами ранее, поэтому публикация этого потребовала дополнительных усилий. Мы приносим извинения за задержку. Мы намеревались разослать это сообщение намного раньше и позаботимся о том, чтобы в будущем мы могли публиковать обновления с учетом этих ограничений.

#### 22 октября 2018 г., 11:12 UTC
Все первичные базы данных снова установлены на восточном побережье США. 

Это привело к тому, что сайт стал гораздо более отзывчивым, так как записи теперь направлялись на сервер базы данных, расположенный в том же физическом центре обработки данных, что и наш уровень приложений. 

Несмотря на то, что это существенно повысило производительность, по-прежнему существовали десятки реплик чтения базы данных, которые отставали от основной на несколько часов. 

Эти отложенные реплики приводили к тому, что пользователи видели несогласованные данные при взаимодействии с нашими службами. Мы распределили нагрузку чтения по большому пулу реплик чтения, и каждый запрос к нашим службам имел хорошие шансы попасть в реплику чтения, которая задерживалась на несколько часов.

На самом деле время, необходимое для репликации, соответствовало функции убывания мощности, а не линейной траектории. 

Из-за увеличения нагрузки записи на наши кластеры баз данных, когда пользователи просыпались и начинали свой рабочий день в Европе и США, процесс восстановления занял больше времени, чем первоначально предполагалось.

#### 22 октября 2018 г., 13:15 UTC
К настоящему времени мы приближались к пиковой нагрузке трафика на GitHub.com. 

Группа реагирования на инциденты обсудила, как действовать дальше. 

Было ясно, что задержки репликации увеличиваются, а не уменьшаются в направлении согласованного состояния. 

Мы начали предоставлять дополнительные реплики чтения MySQL в общедоступном облаке восточного побережья США ранее во время инцидента. 

Как только они стали доступны, стало проще распределять объем запросов на чтение по большему количеству серверов. 

Сокращение совокупного использования реплик чтения позволило репликации наверстать упущенное.

#### 22 октября 2018 г., 16:24 UTC
Как только реплики были синхронизированы, мы выполнили аварийное переключение на исходную топологию, решив немедленные проблемы с задержкой/доступностью.

В рамках сознательного решения отдавать предпочтение целостности данных, а не более короткому периоду инцидента, мы сохранили статус службы красным , пока начали обрабатывать накопившиеся данные.

#### 22 октября 2018 г., 16:45 (всемирное координированное время)
На этом этапе восстановления нам нужно было сбалансировать возросшую нагрузку, представленную отставанием, потенциально перегружая наших партнеров по экосистеме уведомлениями, и как можно быстрее вернуть наши услуги на 100%. 

В очереди было более пяти миллионов событий ловушек и 80 тысяч сборок страниц.

Когда мы повторно включили обработку этих данных, мы обработали около 200 000 полезных нагрузок веб-перехватчиков, которые пережили внутренний TTL и были удалены. Обнаружив это, мы приостановили эту обработку и внесли изменение, чтобы на время увеличить этот TTL.

Чтобы избежать дальнейшего подрыва надежности наших обновлений статуса, мы оставались в ухудшенном статусе до тех пор, пока не завершили обработку всего отставания данных и не убедились, что наши сервисы явно вернулись к нормальному уровню производительности.

#### 22 октября 2018 23:03 UTC
Все ожидающие сборки вебхуков и страниц были обработаны, и была подтверждена целостность и правильная работа всех систем. Статус сайта был обновлен до зеленого .

### Следующие шаги
#### Устранение несоответствий данных
Во время нашего восстановления мы захватили двоичные журналы MySQL, содержащие записи, которые мы сделали на нашем основном сайте, но которые не были реплицированы на наш сайт Западного побережья из каждого затронутого кластера. Общее количество операций записи, которые не были воспроизведены на Западном побережье, было относительно небольшим. Например, один из наших самых загруженных кластеров имел 954 записи в затронутом окне. В настоящее время мы проводим анализ этих журналов и определяем, какие записи могут быть автоматически согласованы, а какие потребуют взаимодействия с пользователями. У нас есть несколько команд, занятых этой работой, и наш анализ уже определил категорию записей, которые с тех пор повторялись пользователем и успешно сохранялись. Как указано в этом анализе, наша основная цель — сохранить целостность и точность данных, которые вы храните на GitHub.






8. Таймлайн (последовательное описание ключевых событий инцидента с указанием времени)

* 2018 21 октября 22:52 UTC
> Из-за кратковременного отсутствия связи между Восточным и Западным ЦОД кластеры БД начали процесс репликации для восстановления целостности БД.
> Резко увеличился трафик между ЦОД и повысилась дополнительная задержка в передаче данных между ЦОД.

* 2018 21 октября 22:54 UTC
> системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в наших системах

* 2018 21 октября 23:02 UTC
> Инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии.
> Несколько инженеров отвечали и работали над сортировкой входящих уведомлений.

* 2018 21 октября 23:07 UTC
> Отвечающая команда решила вручную заблокировать наш внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. 

* 2018 21 октября 23:09 UTC 
> Команда респондентов поместила сайт в желтый статус . Это действие автоматически переводит ситуацию в активный инцидент и отправляет предупреждение координатору инцидентов. 

* 2018 21 октября 23:11 UTC 
> Присоединился координатор инцидента и через две минуты изменил статус решения на красный .

* 2018 21 октября 23:13 UTC
> Инженеры из группы разработки баз данных GitHub приступили к ручной настройке БД Восточного кластера в качестве основной для каждого кластера и перестройки топологии репликации. 
> А также они приостановили репликацию тех записей, которые не были реплицированы на Западное побережье, что предотвратило репликацию новых операций записи обратно на Восточное побережье. 
> Основание такого решения - невозможность справиться с **дополнительной задержкой**, возникающей из-за обмена данными между странами для большинства их вызовов базы данных. Это решение приведет к тому, что сервис станет непригодным для многих пользователей.

* 2018 21 октября 23:19 UTC
> Приостановлены сервисы доставки веб-перехватчика и сборки GitHub Pages для сохранения целостности данных.

* 22 октября 2018 г., 00:05 UTC
> Начало разработки плана по устранению несоответствий данных и синхронизации реплик на обоих сайтах.
> Обновлен статус сайта.
> Проинформировали пользователей о том, что планируется выполнить контролируемый переход на другой ресурс внутренней системы хранения данных.

* 22 октября 2018 г., 00:41 UTC
> Начало процесса резервного копирования для всех затронутых кластеров MySQL.
> Поиск решения для ускорения резервного копирования.

* 22 октября 2018 г., 06:51 UTC
> Завершение восстановление некоторых кластеров из резервных копий в Восточном ЦОД и начало репликации с Западным ЦОД.
> Изменение статуса сайта "ожидаемое время восстановления - два часа"

* 22 октября 2018 07:46 UTC
> Опубликование сообщения в блоге для подачи актального окнтента пользователям.

* 22 октября 2018 г., 11:12 UTC
> Установление всех первичных БД на Восточном ЦОД
> Повышение отзывчивости сайта
> Распределение нагрузки чтения по большому пулу реплик чтения

* 22 октября 2018 г., 13:15 UTC
> Начало предоставления дополнительных реплик чтения MySQL в общедоступном облаке Восточного ЦОД для сокращения совокупного использования реплик

* 22 октября 2018 г., 16:24 UTC
> Выполнено аварийное переключение на исходную топологию.

* 22 октября 2018 г., 16:45
> Корректировка TTL веб-перехватчиков для предотвращения удаления полезных нагрузок веб-перехватчиков.
> Сохранение красного статуса сайта.

* 22 октября 2018 23:03 UTC
> Все ожидающие сборки вебхуков и страниц были обработаны, и была подтверждена целостность и правильная работа всех систем. 
> Статус сайта был обновлен до зеленого.


9. Последующие действия (что нужно предпринять, чтобы инцидент не повторялся)

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

